영화 '다크나이트'의 한 장면(3인칭)을 등장인물인 조커(1인칭)의 시선으로 재구성한 모습.






[충청뉴스 이성현 기자] 영화 속 등장인물의 시선을 내가 직접 경험할 수 있다면 어떨까?


국내 연구진이 일반 영상만으로도 사용자가 직접 보는 시점의 영상을 생성하는 새로운 인공지능 모델을 개발했다.


한국과학기술원(KAIST)은 김재철AI대학원 주재걸 석좌교수 연구팀이 관찰자 시점의 영상만을 활용해 영상 속 인물이 실제로 보고 있었을 장면을 정밀하게 생성하는 인공지능 모델 ‘에고엑스(EgoX)’를 개발했다고 23일 밝혔다.


이번 기술은 단순히 화면을 회전시키는 수준을 넘어 인물의 위치와 자세, 주변 공간의 3차원(3D) 구조를 종합적으로 이해한 뒤 이를 기반으로 1인칭 시점 영상을 재구성한다는 점이 특징이다.


EgoX는 단 하나의 3인칭 시점 영상만으로도 고품질의 1인칭 영상을 생성할 수 있다. 연구팀은 특히 인물의 머리 움직임과 실제 시야 사이의 상관관계를 정밀하게 모델링함으로써 고개를 돌릴 때 시야가 자연스럽게 전환되는 모습까지 사실적으로 구현하는 데 성공했다.


이 기술은 특정 환경에 국한되지 않고 요리, 운동, 작업 등 다양한 일상 상황에서도 안정적인 성능을 보였다. 이를 통해 별도의 웨어러블 장치를 착용하지 않고도 기존에 축적된 영상으로부터 고품질의 1인칭 시점 데이터를 확보할 수 있는 새로운 가능성을 열었다는 평가를 받고 있다.


또 로봇이 사람의 행동을 보고 학습하는 모방 학습의 핵심 데이터로 활용될 수 있어 로봇과 AI 학습 분야에도 기여할 것으로 전망된다.


스포츠 중계나 브이로그를 선수나 주인공의 시점으로 전환하는 등 새로운 형태의 영상 서비스도 가능해질 것으로 기대된다.


주재걸 석좌교수는 “이번 연구는 단순한 영상 변환 기술을 넘어, 인공지능이 사람의 ‘시야’와 ‘공간 이해’를 학습해 재구성했다는 점에서 의미가 크다”며 “앞으로는 기존에 촬영된 영상만으로도 누구나 몰입형 콘텐츠를 제작하고 경험할 수 있는 환경이 열릴 것으로 기대한다”고 설명했다.


이어 “KAIST는 생성형 AI 기반 비디오 기술 분야에서 세계적 경쟁력을 확보해 나갈 것”이라고 덧붙였다.


저작권자 © 충청뉴스 무단전재 및 재배포 금지












이성현 기자


다른기사 보기
 














기사가 
마음에 드셨나요?
 


충청뉴스 좋은 기사 후원하기












1,000원








3,000원








5,000원








10,000원








30,000원








50,000원








직접입력












비회원 약관동의하기






※ 소중한 후원금은 더 좋은 기사를 만드는데 쓰겠습니다.

기사 원본 링크: http://www.ccnnews.co.kr/news/articleView.html?idxno=401926